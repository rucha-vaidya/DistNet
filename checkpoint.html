<section class="main-content">
      <h2>
<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a><b>Project Checkpoint</b></h2>

<h3> Deciding Dataset and Platform (April 11 - April 12) </h3>

<p>Dataset:
After searching about datasets we finalized the CIFAR-10 dataset for the project. We made the decision because CIFAR-10 is a image dataset on which we could use convolutional neural networks. And since CIFAR-10 has 32x32 images, the single node version train in a reasonable amount of time</p>

<p>Platform:
Before decided to use CUDA and openMPI, but since our main focus was on distributing machine learning on several nodes, we didn't want to spend a lot of time, creating different layers of the architecture. We chose to use a machine learning framework that would help us with building the network architecture. Since neither of us had experience working on any deep learning framework, we decided to chose one that had good documentation and strong userbase, and hence finalized on Tensorflow</p>
We are using the following software stack
<ul>
	<li> Python API of Tensorflow 1.0 </li>
	<li> cuDNN 5.1 </li>
	<li> CUDA 8.0 </li>
</ul>
<p> We were initially going to test our implementation on the latedays cluster, but decided to use the AWS cloud/Google cloud platform instead</p>


<h3> Testing the Benchmark Code (April 9 - 11) </h3>

<p>After survey of architectures to experiment on, we decided on Squeezenet as our architecture because of its small size and accuracy similar to Alexnet. Since the number of parameters were minimal, it has a higher chance training speedup due to cluster training. But we were not able to get a the baseline version running on the current version of TensorFlow. Since we were new to TensorFlow, were having to spend lot of time trying to debug the SqueezeNet starter code. To give ourselves more time to work
	on actually building a distributed algorithm, we shifted to a tried and tested Alexnet implementation. We might consider testing our distributed training model for Squeezenet if time permits </p>
	
	
<h3> Revised Project Goals and Parallelism Competition (Present - May 11) </h3>
<ul>
	<li> We believe that we will be able to produce real-time CPU and GPU implementation of Visual Odometry. Once we have this working, we will move on to the next phase, where we will be working on Loop closure. </li>
	<li> We intend to show a demo of real time camera tracking on CPU and GPU. We also intend to show a comparison between pure CPU and GPU based on energy consumption </li>
</ul>



      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/uprasad/CubeRover">CubeRover</a> is maintained by <a href="https://github.com/uprasad">uprasad</a> & <a href="https://github.com/nikithashr">nikithashr</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

  
</section>
