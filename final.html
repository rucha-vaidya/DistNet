

<section class="main-content">
      <h2>
<a id="welcome-to-github-pages" class="anchor" href="#welcome-to-github-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a><b>Final Writeup</b></h2>

<h3>DistNet - Summary</h3>


<p>Distnet displays various techniques used in parallelizing high-accuracy 
  Convolutional Neural Network using a distributed training algorithm on a cluster of 
  nodes and a parameter-server architecture leveraging socket communication.
  The main goal is to find out which approach is beneficial in which scenario in 
  achieving similar accuracy as non-distributed training in lesser amount of time.</p>

<h3>Background</h3>
<p>Neural networks are a set of algorithms, modeled loosely after the human brain, that are designed to recognize patterns. They interpret sensory data through a kind of machine perception, labeling or clustering raw input. The patterns they recognize are numerical, contained in vectors, into which all real-world data, be it images, sound, text or time series, must be translated. Deep neural networks have more than a single hidden layer between the input and the output layer. Training the neural network is done through gradient descent and backpropagation. Deep neural networks with multiple convolution layers and followed by fully connected layers takes a long time to train due to the varying learning rates. To achieve high accuracy, the amount of data fed into these networks is extremely high, making the time for each epoch high. Training AlexNet on a single GPU(NVIDIA K20) takes about 100 epochs (6 days). Long training times for high-accuracy deep neural networks (DNNs) impede research into new DNN architectures and slow the development of high-accuracy DNNs. Hence, we would like to explore the use of a cluster of GPU machines to accelerate the learning. The speed and scalability of distributed algorithms is almost always limited by the overhead of communicating between servers; DNN training is not an exception to this rule. Therefore, the key consideration here is to reduce communication overhead wherever possible, while not degrading the accuracy of the DNN models that we train.
  </p>
  <h4>Parallelism Axis</h4>
    <p>Parallelism in the training deep neural networks can be explored along two axes. Depending on the architecture and communication
        model we choose, the parallelism axis will affect the speedup that can be achieved by learning on a cluster as opposed to a single node.
        The two kinds of parallelism are :
    </p>
     <ul> 
      <li>Model Parallelism: <br>
        In this type of Parallelism different parts of the model that is being learnt in the neural network are computed by different 
          machines in the distributed system. Model parallelism is efficient when the amount of computation per neuron 
          activity is high, because neuron activity is the unit being communicated.
         </li>
         <img src="assets/Model_parallelism.png" height="50%" width="50%"/>
      <li>Data Parallelism: <br>
         In this type of parallelism each machine in the distributed system has a copy of the entire model but the data 
         to be trained upon is distributed over the machines and the results are combined from each. Data parallelism is efficient when the
         amount of computation per weight is high, because the weight is the unit being communicated.</li>
          <img src="assets/data_parallelism.png" height="50%" width="50%"/>
    </ul>    
      

<h3>Approach</h3>
      
      <table class="pure-table pure-table-horizontal">
    <thead>
        <tr bgcolor="#f0f0f0">
            <th>Item</th>
            <th>Description</th>
           
        </tr>
    </thead>

    <tbody>
        <tr>
            
            <td>Dataset</td>
            <td>CIFAR-10. We chose this because it can be used for training in a suitable amount of time to get a high accuracy</td>
        </tr>

        <tr bgcolor="#f0f0f0">
            
            <td>Architecture</td>
            <td>AlexNet</td>
       </tr>

        <tr>
            <td>Language</td>
            <td>Python</td>
        </tr>
        
        <tr bgcolor="#f0f0f0">
         
            <td>Machine Intelligence Library </td>
            <td>TensorFlow</td>
        </tr>
        <tr>
         
            <td>Target Machines</td>
            <td>Nodes with atleast a single GPU</td>
        </tr>

        <tr bgcolor="#f0f0f0">
      
            <td>Message Passing</td>
            <td>Native Socket Communication</td> 
        </tr>
    </tbody>
</table>

 <h4>System Architecture Diagram</h4>  
      <div class="box" style="margin:4; padding:4">
<img src="assets/System_Arch.png"/>
            </div>
      <p>The image describes the architecture of the system which consists of multiple workers running TensorFlow instances calculating gradient values and sending them to the Parameter Server(s)</p>
      <!--<a id="designer-templates" class="anchor" href="#designer-templates" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pre-process Depth</h3> -->

  <h4>Challenges</h4>
      <ol>
      <li>Deciding on a reliable and fast communication mechanism. Many of the wrappers around low-level sockets come with overheads and poor reliability(for eg. python bindings for MPI.
            Hence, we decided to use the low-level socket API directly, and write explicit functions to safely receive all the intended data</li>
       <li>Due to limitations of time and resources, we are implementing a distributed training algorithm for a relatively smaller data set - CIFAR-10. This allows us to spend sufficient time in
            developing the distributed algorithms rather than waiting for the training to complete. The results of these smaller data sets will reflect even more positively
            for larger data sets(more machines, more data in working set).</li>  
      <li>Our parameter server implementation uses multiple processes, shared memory and queues, as opposed to multi-threading, this is because
            a multi-threading pythonic server cannot utilize multiple cores because of the Global Interpreter Lock</li>
       <li>Splitting the tensorflow computation graph without tensorflow knowing about it is a difficult task. Multiple partial runs on the same graph are not fully supported, because of which we had to 
            ensure that we call compute and apply gradients on two different machines for all our implementations.</li>
      
      </ol>

 
 <h4>Baseline Implementation</h4>
      <p>We use the CIFAR-10 TensorFlow tutorial code that implements the AlexNet running on a single GPU as our baseline implementation</p>

  <h4>Axis of Parallelism Used</h4>
      <p>We have used the Data Parallelism approach as a major axis of parallelism. The CNN datasets generally have large sizes and thus dividing training data among the workers makes it fit in memory and also help to go over data faster. Using multiple workers helps us look at higher aggregate size batches of data at once,
         thereby reducing the loss faster, and subsequently reaching the said accuracy faster.</p>

   <h4>Exploring Design Space in Parallelization</h4>
      <div class="box" style="margin:4; padding:4">
<img src="assets/design_space.png"/>
            </div>
      <p>The project explores the various design decisions available in parallelizing the CNN training. Beginning with single Parameter Server, we tried the Synchronous and Asynchronous Stochastic Gradient Descent. In synchronous approach the workers go in sync with each other whereas in asynchronous the workers run iterations on their own speed without waiting for anyone else.
In the asynchronous case we tried the Locked version wherein every read and write of the parameter values at the Parameter Server is protected by a lock.  In the lock-free version similar to Project Adam we removed the locked access. 
In addition another Lazy Update approach was tested in which the parameter server handling the workers immediately sent the parameter values and a background process lazily applied the gradients received later. 

Continuing we also tried multiple parameter server models wherein the parameter values were sharded across two parameter servers. </p>
       <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/rucha-vaidya/parallel-final">DistNet</a> is maintained by <a href="https://github.com/NasrinJaleel93">NasrinJaleel93</a> and <a href="https://github.com/rucha-vaidya">rucha-vaidya</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    
